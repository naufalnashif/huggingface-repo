{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9QuTAIcOp/E0LQPbpOxvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naufalnashif/huggingface-repo/blob/main/scraping_playstore_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Dependencies"
      ],
      "metadata": {
        "id": "ZHq2QNDvOXW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "nL6KEG8jNQT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Syntax Streamlit"
      ],
      "metadata": {
        "id": "ZHP56AWBPo78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G_ojj6w7IMk",
        "outputId": "72ae0773-02e7-456f-d0cf-63f5ff53bdef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scraping-playstore-reviews.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile scraping-playstore-reviews.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "#from google_play_scraper import app, Sort, reviews, permission, reviews_all, search\n",
        "from google_play_scraper import app, Sort, reviews, reviews_all, permissions, search\n",
        "import re\n",
        "\n",
        "#---------------------------------------------func----------------------------------\n",
        "\n",
        "@st.cache_data\n",
        "def get_url_by_app_name(nama_apl):\n",
        "    \"\"\"\n",
        "    Mengembalikan URL aplikasi berdasarkan nama aplikasi dari kamus.\n",
        "    Parameters:\n",
        "    - nama_apl (str): Nama aplikasi yang dicari.\n",
        "    - aplikasi_dict (dict): Kamus yang memetakan nama aplikasi ke URL.\n",
        "    Returns:\n",
        "    - str or None: URL aplikasi atau None jika tidak ditemukan.\n",
        "    \"\"\"\n",
        "    list_url = [\n",
        "        'https://play.google.com/store/apps/details?id=com.shopee.id',\n",
        "        'https://play.google.com/store/apps/details?id=com.tokopedia.tkpd',\n",
        "        'https://play.google.com/store/apps/details?id=com.amazon.mShop.android.shopping',\n",
        "        'https://play.google.com/store/apps/details?id=com.grabtaxi.passenger'\n",
        "    ]\n",
        "    aplikasi_dict = {\n",
        "        'Shopee': list_url[0],\n",
        "        'Tokopedia': list_url[1],\n",
        "        'Amazon': list_url[2],\n",
        "        'Grab': list_url[3]\n",
        "    }\n",
        "    return aplikasi_dict.get(nama_apl, None)\n",
        "\n",
        "@st.cache_data\n",
        "def extract_app_id(play_store_url):\n",
        "    # Definisikan pola ekspresi reguler untuk menemukan ID aplikasi\n",
        "    pattern = r'id=([a-zA-Z0-9._]+)'\n",
        "\n",
        "    # Gunakan ekspresi reguler untuk mencocokkan pola dalam URL\n",
        "    match = re.search(pattern, play_store_url)\n",
        "\n",
        "    # Periksa apakah ada kecocokan dan kembalikan ID aplikasi jika ada\n",
        "    if match:\n",
        "        app_id = match.group(1)\n",
        "        return app_id\n",
        "    else:\n",
        "        return None\n",
        "@st.cache_data(show_spinner = 'On progress, please wait...')\n",
        "def scraping_func(app_id, bahasa, negara, filter_score, jumlah):\n",
        "    filter_score = None if filter_score == \"Semua Rating\" else filter_score\n",
        "\n",
        "    rws, token = reviews(\n",
        "        app_id,\n",
        "        lang=bahasa,\n",
        "        country=negara,\n",
        "        sort=Sort.NEWEST,\n",
        "        filter_score_with=filter_score,\n",
        "        count=jumlah\n",
        "    )\n",
        "\n",
        "    scraping_done = bool(rws)\n",
        "\n",
        "    return rws, token, scraping_done\n",
        "\n",
        "@st.cache_data(show_spinner = 'On progress, please wait...')\n",
        "def scraping_all_func(app_id, bahasa, negara, filter_score, sleep = 0):\n",
        "    filter_score = None if filter_score == \"Semua Rating\" else filter_score\n",
        "\n",
        "    rws = reviews_all(\n",
        "        app_id,\n",
        "        sleep_milliseconds=sleep, # defaults to 0\n",
        "        lang=bahasa,\n",
        "        country=negara,\n",
        "        filter_score_with=filter_score,\n",
        "    )\n",
        "\n",
        "    scraping_done = bool(rws)\n",
        "\n",
        "    return rws, scraping_done\n",
        "\n",
        "@st.cache_data\n",
        "def buat_chart(df, target_year):\n",
        "    st.write(f\"Bar Chart Tahun {target_year}:\")\n",
        "\n",
        "    # Ambil bulan\n",
        "    df['at'] = pd.to_datetime(df['at'])  # Convert 'at' column to datetime\n",
        "    df['month'] = df['at'].dt.month\n",
        "    df['year'] = df['at'].dt.year\n",
        "\n",
        "    # Filter DataFrame for the desired year\n",
        "    df_filtered = df[df['year'] == target_year]\n",
        "\n",
        "    # Check if data for the target year is available\n",
        "    if df_filtered.empty:\n",
        "        st.warning(f\"Tidak ada data untuk tahun {target_year}.\")\n",
        "        return\n",
        "\n",
        "    # Mapping nilai bulan ke nama bulan\n",
        "    bulan_mapping = {\n",
        "        1: f'Januari {target_year}',\n",
        "        2: f'Februari {target_year}',\n",
        "        3: f'Maret {target_year}',\n",
        "        4: f'April {target_year}',\n",
        "        5: f'Mei {target_year}',\n",
        "        6: f'Juni {target_year}',\n",
        "        7: f'Juli {target_year}',\n",
        "        8: f'Agustus {target_year}',\n",
        "        9: f'September {target_year}',\n",
        "        10: f'Oktober {target_year}',\n",
        "        11: f'November {target_year}',\n",
        "        12: f'Desember {target_year}'\n",
        "    }\n",
        "\n",
        "    # Mengganti nilai dalam kolom 'month' menggunakan mapping\n",
        "    df_filtered['month'] = df_filtered['month'].replace(bulan_mapping)\n",
        "\n",
        "    # Menentukan warna untuk setiap kategori dalam kolom 'score'\n",
        "    warna_score = {\n",
        "        1: '#FF9AA2',\n",
        "        2: '#FFB7B2',\n",
        "        3: '#FFDAC1',\n",
        "        4: '#E2F0CB',\n",
        "        5: '#B5EAD7'\n",
        "    }\n",
        "\n",
        "    # Sorting unique scores\n",
        "    unique_scores = sorted(df_filtered['score'].unique())\n",
        "\n",
        "    # Ensure months are in the correct order\n",
        "    months_order = [\n",
        "        f'Januari {target_year}', f'Februari {target_year}', f'Maret {target_year}', f'April {target_year}', f'Mei {target_year}', f'Juni {target_year}',\n",
        "        f'Juli {target_year}', f'Agustus {target_year}', f'September {target_year}', f'Oktober {target_year}', f'November {target_year}', f'Desember {target_year}'\n",
        "    ]\n",
        "\n",
        "    # Sort DataFrame based on the custom order of months\n",
        "    df_filtered['month'] = pd.Categorical(df_filtered['month'], categories=months_order, ordered=True)\n",
        "    df_filtered = df_filtered.sort_values('month')\n",
        "\n",
        "    # Create a bar chart with stacking and manual colors\n",
        "    st.bar_chart(\n",
        "        df_filtered.groupby(['month', 'score']).size().unstack().fillna(0),\n",
        "        color=[warna_score[score] for score in unique_scores]\n",
        "    )\n",
        "#--------------------------------------------UI---------------------------------------\n",
        "# Streamlit UI\n",
        "st.title(\"Data Everywhere : Scraping Playstore Reviews\")\n",
        "scraping_done = False\n",
        "with st.sidebar :\n",
        "    with st.expander(\"Scraping Settings :\"):\n",
        "        scrape = st.selectbox(\"PIlih Metode :\", (\"Semua Reviews\", \"Estimasi Data\"), index = 1)\n",
        "        aplikasi = st.radio(\n",
        "            \"Pilih Input :\",\n",
        "            [\"Defaults\", \"Custom URL\"], index = 0,\n",
        "            captions = [\"Shopee, Tokopedia, Amazon, Grab\", \"Tambahkan URL Manual\"])\n",
        "        if aplikasi == \"Defaults\" :\n",
        "            nama_apl = st.selectbox(\"Pilih Aplikasi :\", ('Shopee', 'Tokopedia', 'Amazon', 'Grab'))\n",
        "            if nama_apl :\n",
        "                url = get_url_by_app_name(nama_apl)\n",
        "        elif aplikasi == \"Custom URL\":\n",
        "            url = st.text_input(\"Masukkan URL Aplikasi Pada Web Playstore :\", 'https://play.google.com/store/apps/details?id=com.shopee.id')\n",
        "        if scrape == \"Estimasi Data\" :\n",
        "            jumlah = st.number_input(\"Masukkan Estimasi Banyak Data :\", min_value = 10, max_value = 10000, step = 10, placeholder=\"Type a number...\")\n",
        "    with st.expander(\"Preference Settings :\"):\n",
        "        if scrape == \"Semua Reviews\" :\n",
        "            sleep = st.number_input(\"Masukkan sleep (milisecond) :\", min_value = 1, max_value = 1000, step = 10, placeholder=\"Type a number...\")\n",
        "        bahasa = st.selectbox(\"Pilih Bahasa:\", ('en', 'id'))\n",
        "        negara = st.selectbox(\"Pilih Negara :\", ('us', 'id'))\n",
        "        filter_score = st.selectbox(\"Pilih Rating :\", ('Semua Rating', 1, 2, 3, 4, 5))\n",
        "        target_year = st.selectbox(\"Pilih Tahun Bar Chart :\", (2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025), index = 7)\n",
        "        download_format = st.selectbox(\"Pilih Format Unduhan :\", [\"XLSX\", \"CSV\", \"JSON\"])\n",
        "    st.info('Tekan \"Mulai Scraping\" kembali jika tampilan menghilang ', icon=\"‚ÑπÔ∏è\")\n",
        "\n",
        "    if url and bahasa and negara and filter_score and download_format:\n",
        "        if st.button (\"Mulai Scraping\") :\n",
        "            app_id = extract_app_id(url)\n",
        "            if scrape == \"Semua Reviews\" :\n",
        "                reviews, scraping_done = scraping_all_func(app_id, bahasa, negara, filter_score, sleep)\n",
        "                df = pd.DataFrame(reviews)\n",
        "            elif scrape == \"Estimasi Data\":\n",
        "                reviews, token, scraping_done = scraping_func(app_id, bahasa, negara, filter_score, jumlah)\n",
        "                df = pd.DataFrame(reviews)\n",
        "            else :\n",
        "                st.warning(\"Masukkan pilihan yang valid\")\n",
        "    else :\n",
        "        st.error(\"Mohon Masukkan Parameter.\")\n",
        "\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\"üìã Documentation\", \"üìà Results\", \"ü§µ Creator\", \"üîç More\"])\n",
        "with tab1:\n",
        "    @st.cache_resource\n",
        "    def tab_1():\n",
        "        st.header(\"Documentation:\")\n",
        "        '''\n",
        "        Langkah - langkah :\n",
        "        1. Buka sidebar sebelah kiri\n",
        "        2. Buka Scraping Settings\n",
        "        3. Hati - hati jika menggunakan \"Semua Reviews\" karena bisa berjumlah jutaan data\n",
        "        4. Masukkan URL app pada situs playstore\n",
        "        5. Sesuaikan bahasa, negara, dan rating yang akan diambil\n",
        "        6. Pilih tahun bar chart\n",
        "        7. Pilih format unduhan\n",
        "        8. Klik \"Mulai Scraping\"\n",
        "        9. Buka tab Results\n",
        "        '''\n",
        "    tab_1()\n",
        "#-------------------------------------------BE----------------------------------------\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Results:\")\n",
        "\n",
        "    if scraping_done == True:\n",
        "        with st.expander(f\"Hasil Scraping {app_id}:\"):\n",
        "            buat_chart(df, target_year)\n",
        "            st.write(df)\n",
        "\n",
        "            if download_format == \"XLSX\":\n",
        "                # Clean the data to remove illegal characters\n",
        "                cleaned_data = df.applymap(lambda x: \"\".join(char for char in str(x) if char.isprintable()))\n",
        "\n",
        "                # Save the cleaned data to Excel\n",
        "                cleaned_data.to_excel(f\"hasil_scraping_{app_id}.xlsx\", index=False)\n",
        "\n",
        "                # Provide the download button for the cleaned Excel file\n",
        "                st.download_button(label=f\"Unduh XLSX ({len(reviews)} data)\", data=open(f\"hasil_scraping_{app_id}.xlsx\", \"rb\").read(), key=\"xlsx_download\", file_name=f\"hasil_scraping_{app_id}.xlsx\")\n",
        "\n",
        "            elif download_format == \"CSV\":\n",
        "                csv = df.to_csv(index=False)\n",
        "\n",
        "                # Provide the download button for the CSV file\n",
        "                st.download_button(label=f\"Unduh CSV ({len(reviews)} data)\", data=csv, key=\"csv_download\", file_name=f\"hasil_scraping_{app_id}.csv\")\n",
        "\n",
        "            elif download_format == \"JSON\":\n",
        "                json_data = df.to_json(orient=\"records\")\n",
        "\n",
        "                # Provide the download button for the JSON file\n",
        "                st.download_button(label=f\"Unduh JSON ({len(reviews)} data)\", data=json_data, key=\"json_download\", file_name=f\"hasil_scraping_{app_id}.json\")\n",
        "\n",
        "    else:\n",
        "        st.info(\"Tidak ada data\")\n",
        "\n",
        "with tab3:\n",
        "    @st.cache_resource\n",
        "    def tab_3():\n",
        "        st.header(\"Profile:\")\n",
        "        st.image('https://raw.githubusercontent.com/naufalnashif/naufalnashif.github.io/main/assets/img/my-profile-sidang-idCard-crop.JPG', caption='Naufal Nashif')\n",
        "        st.subheader('Hello, nice to meet you !')\n",
        "        # Tautan ke GitHub\n",
        "        github_link = \"https://github.com/naufalnashif/\"\n",
        "        st.markdown(f\"GitHub: [{github_link}]({github_link})\")\n",
        "\n",
        "        # Tautan ke Instagram\n",
        "        instagram_link = \"https://www.instagram.com/naufal.nashif/\"\n",
        "        st.markdown(f\"Instagram: [{instagram_link}]({instagram_link})\")\n",
        "\n",
        "        # Tautan ke Website\n",
        "        website_link = \"https://naufalnashif.netlify.app/\"\n",
        "        st.markdown(f\"Website: [{website_link}]({website_link})\")\n",
        "    tab_3()\n",
        "\n",
        "with tab4:\n",
        "    @st.cache_resource\n",
        "    def tab_4():\n",
        "        st.header(\"More:\")\n",
        "        more1, more2, more3 = st.columns(3)\n",
        "        with more1 :\n",
        "            st.image('https://raw.githubusercontent.com/naufalnashif/huggingface-repo/main/assets/img/sentiment-analysis-biskita.png', caption = 'Sentiment Analysis Web App')\n",
        "            more1_link = \"https://huggingface.co/spaces/naufalnashif/sentiment-analysis-ensemble-model\"\n",
        "            st.markdown(f\"[{more1_link}]({more1_link})\")\n",
        "        with more2 :\n",
        "            st.image('https://raw.githubusercontent.com/naufalnashif/huggingface-repo/main/assets/img/scraping-news-headline.png', caption = 'Scraping News Headline')\n",
        "            more2_link = \"https://huggingface.co/spaces/naufalnashif/scraping-news-headline\"\n",
        "            st.markdown(f\"[{more2_link}]({more2_link})\")\n",
        "        with more3 :\n",
        "            st.image('https://raw.githubusercontent.com/naufalnashif/huggingface-repo/main/assets/img/scraping-ecommerce.png', caption = 'Scraping Ecommerce Product')\n",
        "            more3_link = \"https://huggingface.co/spaces/naufalnashif/scraping-ecommerce-2023\"\n",
        "            st.markdown(f\"[{more3_link}]({more3_link})\")\n",
        "    tab_4()\n",
        "\n",
        "# Garis pemisah\n",
        "st.divider()\n",
        "st.write('Thank you for trying the demo!')\n",
        "st.caption('Best regards, Naufal Nashif :sunglasses: | ¬©Ô∏è 2023')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Untuk run\n",
        "- Jalankan kedua cell\n",
        "- cell pertama akan menggenerate IP Address\n",
        "- cell kedua akan mendapatkan url, klik dan masukkan output cell pertama kedalam tunnel password"
      ],
      "metadata": {
        "id": "KntV8VPsPtUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KWkKRo2PwKV",
        "outputId": "670afb1d-f7a2-494c-8069-e48e15c580f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.245.43.177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run scraping-playstore-reviews.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsZQ9r-hPxDy",
        "outputId": "97b7e4de-7d6c-4892-8d0d-cc5ea119fd42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l[..................] / rollbackFailedOptional: verb npm-session 3009fe9b3fd6bbb\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session 3009fe9b3fd6bbb\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session 3009fe9b3fd6bbb\u001b[0m\u001b[K\r[..................] \\ rollbackFailedOptional: verb npm-session 3009fe9b3fd6bbb\u001b[0m\u001b[K\r\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.245.43.177:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.472s\n",
            "your url is: https://beige-shoes-beg.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}